{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    player = None\n",
    "    slot = None\n",
    "    arms = 0\n",
    "    times = 0\n",
    "    \n",
    "    def __init__(self, player, slot, arms, times):\n",
    "        self.player = player\n",
    "        self.slot = slot\n",
    "        self.arms = arms\n",
    "        self.times = times\n",
    "        \n",
    "    def play(self):\n",
    "        for _ in range(self.times):\n",
    "            self.turn()\n",
    "    \n",
    "    def turn(self):\n",
    "        self.player.update_probs()\n",
    "        \n",
    "        rewards = self.slot.return_rewards(self.player.get_probs())\n",
    "        self.player.pull_arm(rewards)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.player.earned_rewards.sum()\n",
    "\n",
    "class Player:\n",
    "    weightss = None\n",
    "    probss = None\n",
    "    cumulative_rewardss = None\n",
    "    choiced_arms = np.array([])\n",
    "    earned_rewards = np.array([])\n",
    "    \n",
    "    def __init__(self, arms):\n",
    "        initial_weights = np.ones(arms) / arms\n",
    "        self.weightss = initial_weights.reshape(1,-1)\n",
    "        self.probss = np.empty((0,arms),float)\n",
    "        self.cumulative_rewardss = np.zeros(arms).reshape(1,-1)\n",
    "        \n",
    "    def get_weights(self):\n",
    "        return self.weightss[-1]\n",
    "\n",
    "    def get_probs(self):\n",
    "        return self.probss[-1]\n",
    "\n",
    "class Hedge(Player):\n",
    "    def update_probs(self):\n",
    "        weights = self.get_weights()\n",
    "        probs = weights / weights.sum()\n",
    "        self.probss = np.vstack((self.probss, probs))\n",
    "    \n",
    "    def update_weights(self, rewards):\n",
    "        weights = self.get_weights()\n",
    "        new_weights = weights * np.exp(rewards)\n",
    "        self.weightss = np.vstack((self.weightss, new_weights))\n",
    "        \n",
    "    def pull_arm(self, rewards):\n",
    "        probs = self.get_probs()\n",
    "        choiced_arm = np.random.choice(len(probs), p=probs)\n",
    "        self.choiced_arms = np.append(self.choiced_arms, choiced_arm)\n",
    "        reward = rewards[choiced_arm]\n",
    "        self.earned_rewards = np.append(self.earned_rewards, reward)\n",
    "        \n",
    "        self.update_weights(rewards)\n",
    "        \n",
    "class Slot:\n",
    "    \n",
    "    rewardss = None\n",
    "    \n",
    "    def __init__(self,arms):\n",
    "        self.rewardss = np.empty((0,arms), float)\n",
    "        \n",
    "class Random(Slot):\n",
    "    def return_rewards(self, probs):\n",
    "        rewards = np.zeros(len(probs))\n",
    "        idx = np.random.randint(0, len(probs))\n",
    "        rewards[idx] = 1\n",
    "        self.rewardss = np.append(self.rewardss, rewards.reshape(1,-1), axis=0)\n",
    "        \n",
    "        return rewards\n",
    "\n",
    "class FixedProbs(Slot):\n",
    "    probs = None\n",
    "    def __init__(self, probs):\n",
    "        self.rewardss = np.empty((0,len(probs)), float)\n",
    "        self.probs = probs\n",
    "        \n",
    "    def return_rewards(self, _):\n",
    "        idx = np.random.choice(len(self.probs), p=self.probs)\n",
    "        rewards = np.zeros(len(self.probs))\n",
    "        rewards[idx] = 1\n",
    "        self.rewardss = np.append(self.rewardss, rewards.reshape(1,-1), axis=0)\n",
    "        \n",
    "        return rewards\n",
    "    \n",
    "class AdaptiveAdversary(Slot):\n",
    "    def return_rewards(self, probs):\n",
    "        # 最も確率が低いアームのindexを取得。複数ある場合はrandomに選ぶ。\n",
    "        min_index = np.random.choice(np.flatnonzero(probs == probs.min()))\n",
    "        rewards = np.zeros(len(probs))\n",
    "        rewards[min_index] = 1\n",
    "        self.rewardss = np.append(self.rewardss, rewards.reshape(1,-1), axis=0)\n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1アームだけ報酬でやすい\n",
    "arms = 5\n",
    "times = 1000\n",
    "player = Hedge(arms)\n",
    "\n",
    "probs = np.array([0.5,0.125,0.125,0.125,0.125])\n",
    "slot = FixedProbs(probs)\n",
    "\n",
    "game = Game(player, slot, arms, times)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 敵対的\n",
    "arms = 5\n",
    "times = 1000\n",
    "player = Hedge(arms)\n",
    "\n",
    "slot = AdaptiveAdversary(arms)\n",
    "game = Game(player, slot, arms, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200., 200., 200., 200., 200.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.slot.rewardss.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プレイヤーがアームを引く確率は累積報酬のみで決まる。\n",
    "# プレイヤーが引く確率が低いアーム（＝累積報酬が最も少ないアーム）に報酬を設定することになるため\n",
    "# 敵対者は各アームの累積報酬は等しくなるように設定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
