{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Games:\n",
    "    \n",
    "    player_class = None\n",
    "    slot_class = None\n",
    "    arms = 0\n",
    "    times = 0\n",
    "    count = 0\n",
    "    expected_rewards_arms = None\n",
    "    expected_earned_rewards = None\n",
    "\n",
    "    def __init__(self, player_class, slot_class, arms, times, count):\n",
    "        self.player_class = player_class\n",
    "        self.slot_class = slot_class\n",
    "        self.arms = arms\n",
    "        self.times = times\n",
    "        self.count = count\n",
    "        self.expected_rewards = np.empty(0, float)\n",
    "        self.expected_rewards_arms = np.empty((0, arms), float)\n",
    "        \n",
    "    def execute(self):\n",
    "        for _ in range(count):\n",
    "            game = Game(self.player_class, self.slot_class, self.arms, self.times)\n",
    "            game.play()\n",
    "            \n",
    "            expected_reward_arms = game.player.cal_expected_reward_arms()\n",
    "            self.expected_rewards_arms = np.append(self.expected_rewards_arms, expected_reward_arms)\n",
    "            \n",
    "            expected_reward = game.player.cal_expected_reward()\n",
    "            self.expected_earned_rewards = np.append(self.expected_rewards, expected_reward)\n",
    "            \n",
    "            \n",
    "    def pseudo_regret(self):\n",
    "        return self.max_arm_expected_rewards_mean() + self.expected_rewards_mean()\n",
    "        \n",
    "    def max_arm_expected_rewards_mean(self):\n",
    "        return self.expected_rewardss_arms.mean(axis=0).max()\n",
    "    \n",
    "    def expected_rewards_mean(self):\n",
    "        return self.expected_rewards.mean()\n",
    "\n",
    "class Game:\n",
    "    player = None\n",
    "    slot = None\n",
    "    arms = 0\n",
    "    times = 0\n",
    "    \n",
    "    def __init__(self, player_class, slot, arms, times):\n",
    "        self.player = player_class(arms,)\n",
    "        self.slot = slot_class()\n",
    "        self.arms = arms\n",
    "        self.times = times\n",
    "        \n",
    "    def play(self):\n",
    "        for _ in range(self.times):\n",
    "            self.turn()\n",
    "    \n",
    "    def turn(self):\n",
    "        self.player.update_probs()\n",
    "        \n",
    "        rewards = self.slot.return_rewards(self.player.get_probs())\n",
    "        self.player.pull_arm(rewards)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.player.earned_rewards.sum()\n",
    "    \n",
    "class Player:\n",
    "    weightss = None\n",
    "    probss = None\n",
    "    cumulative_rewardss = None\n",
    "    choiced_arms = np.array([])\n",
    "    earned_rewards = np.array([])\n",
    "    expected_rewardss = None\n",
    "    \n",
    "    def __init__(self, arms):\n",
    "        initial_weights = np.ones(arms) / arms\n",
    "        self.weightss = initial_weights.reshape(1,-1)\n",
    "        self.probss = np.empty((0,arms),float)\n",
    "        self.cumulative_rewardss = np.zeros(arms).reshape(1,-1)\n",
    "        self.expected_rewardss = np.empty((0,arms), float)\n",
    "        \n",
    "    def get_weights(self):\n",
    "        return self.weightss[-1]\n",
    "\n",
    "    def get_probs(self):\n",
    "        return self.probss[-1]\n",
    "    \n",
    "    def cal_expected_rewards(self, probs, rewards):\n",
    "        expected_rewards = probs * rewards\n",
    "        return expected_rewards\n",
    "    \n",
    "    def cal_expected_reward(self):\n",
    "        reward = self.expected_rewardss.sum()\n",
    "        return reward\n",
    "\n",
    "    def cal_expected_reward_arms(self):\n",
    "        reward_arms = self.expected_rewardss.sum(axis=0)\n",
    "        return reward_arms\n",
    "\n",
    "        \n",
    "class Slot:\n",
    "    \n",
    "    rewardss = None\n",
    "    \n",
    "    def __init__(self,arms):\n",
    "        self.rewardss = np.empty((0,arms), float)\n",
    "        \n",
    "class Random(Slot):\n",
    "    def return_rewards(self, probs):\n",
    "        rewards = np.zeros(len(probs))\n",
    "        idx = np.random.randint(0, len(probs))\n",
    "        rewards[idx] = 1\n",
    "        self.rewardss = np.append(self.rewardss, rewards.reshape(1,-1), axis=0)\n",
    "        \n",
    "        return rewards\n",
    "\n",
    "# class FixedProbs(Slot):\n",
    "#     probs = None\n",
    "#     def __init__(self, probs):\n",
    "#         self.rewardss = np.empty((0,len(probs)), float)\n",
    "#         self.probs = probs\n",
    "        \n",
    "#     def return_rewards(self, _):\n",
    "#         idx = np.random.choice(len(self.probs), p=self.probs)\n",
    "#         rewards = np.zeros(len(self.probs))\n",
    "#         rewards[idx] = 1\n",
    "#         self.rewardss = np.append(self.rewardss, rewards.reshape(1,-1), axis=0)\n",
    "        \n",
    "#         return rewards\n",
    "    \n",
    "class AdaptiveAdversary(Slot):\n",
    "    def return_rewards(self, probs):\n",
    "        # 最も確率が低いアームのindexを取得。複数ある場合はrandomに選ぶ。\n",
    "        min_index = np.random.choice(np.flatnonzero(probs == probs.min()))\n",
    "        rewards = np.zeros(len(probs))\n",
    "        rewards[min_index] = 1\n",
    "        self.rewardss = np.append(self.rewardss, rewards.reshape(1,-1), axis=0)\n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_hedge(eta):\n",
    "    class Hedge(Player):\n",
    "\n",
    "        eta = 1\n",
    "\n",
    "        def __init__(self, arms, eta=1):\n",
    "            super().__init__(arms)\n",
    "            self.eta = eta\n",
    "\n",
    "        def update_probs(self):\n",
    "            weights = self.get_weights()\n",
    "            probs = weights / weights.sum()\n",
    "            self.probss = np.vstack((self.probss, probs))\n",
    "\n",
    "        def update_weights(self, rewards):\n",
    "            weights = self.get_weights()\n",
    "            new_weights = weights * np.exp(rewards * self.eta)\n",
    "            self.weightss = np.vstack((self.weightss, new_weights))\n",
    "\n",
    "        def pull_arm(self, rewards):\n",
    "            probs = self.get_probs()\n",
    "            choiced_arm = np.random.choice(len(probs), p=probs)\n",
    "            self.choiced_arms = np.append(self.choiced_arms, choiced_arm)\n",
    "            reward = rewards[choiced_arm]\n",
    "            self.earned_rewards = np.append(self.earned_rewards, reward)\n",
    "\n",
    "            self.update_weights(rewards)\n",
    "\n",
    "            expected_rewards = self.cal_expected_rewards(probs, rewards)\n",
    "            self.expected_rewardss = np.vstack((self.expected_rewardss, expected_rewards))\n",
    "\n",
    "    return Hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixed_probs_class(probs):\n",
    "    class FixedProbs(Slot):\n",
    "        def __init__(self):\n",
    "            self.rewardss = np.empty((0,len(self.probs)), float)\n",
    "            self.probs = probs\n",
    "            \n",
    "        def return_rewards(self, _):\n",
    "            idx = np.random.choice(len(self.probs), p=self.probs)\n",
    "            rewards = np.zeros(len(self.probs))\n",
    "            rewards[idx] = 1\n",
    "            self.rewardss = np.append(self.rewardss, rewards.reshape(1,-1), axis=0)\n",
    "\n",
    "            return rewards\n",
    "    \n",
    "    return FixedProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update_probs() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1c389a82dd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-2927bd7e5d5f>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslot_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mexpected_reward_arms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_expected_reward_arms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2927bd7e5d5f>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2927bd7e5d5f>\u001b[0m in \u001b[0;36mturn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_rewards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: update_probs() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "# 1アームだけ報酬でやすい\n",
    "arms = 5 \n",
    "times = 1000\n",
    "count = 100\n",
    "\n",
    "eta = 0.7\n",
    "player = create_player_hedge(eta)\n",
    "\n",
    "probs = np.array([0.5,0.125,0.125,0.125,0.125])\n",
    "slot = create_fixed_probs_class(probs)\n",
    "\n",
    "games = Games(player, slot, arms, times, count)\n",
    "games.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1アームだけ報酬でやすい\n",
    "arms = 5 \n",
    "times = 1000\n",
    "eta = 0.7\n",
    "player = Hedge(arms,eta)\n",
    "\n",
    "probs = np.array([0.5,0.125,0.125,0.125,0.125])\n",
    "slot = FixedProbs(probs)\n",
    "\n",
    "game = Game(player, slot, arms, times)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.player.expected_rewardss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etaを微小な値にすると重みが更新されない\n",
    "arms = 5\n",
    "times = 1000\n",
    "eta = 0.000001\n",
    "player = Hedge(arms,eta)\n",
    "\n",
    "probs = np.array([0.5,0.125,0.125,0.125,0.125])\n",
    "slot = FixedProbs(probs)\n",
    "\n",
    "game = Game(player, slot, arms, times)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.player.weightss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 敵対的\n",
    "arms = 5\n",
    "times = 1000\n",
    "eta = 0.7\n",
    "player = Hedge(arms, eta)\n",
    "\n",
    "slot = AdaptiveAdversary(arms)\n",
    "game = Game(player, slot, arms, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.slot.rewardss.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プレイヤーがアームを引く確率は累積報酬のみで決まる。\n",
    "# プレイヤーが引く確率が低いアーム（＝累積報酬が最も少ないアーム）に報酬を設定することになるため\n",
    "# 敵対者は各アームの累積報酬は等しくなるように設定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
